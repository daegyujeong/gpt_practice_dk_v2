{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1)\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(\n",
    "    llm=llm,\n",
    "    max_token_limit=120,\n",
    "    return_messages=True,\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Discribe the moive as 3 emojis. e.g) train to Busan = ğŸš‚ğŸ§Ÿâ€â™‚ï¸ğŸ‡°ğŸ‡·\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def load_memory(_):\n",
    "    return memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "\n",
    "chain = RunnablePassthrough.assign(history=load_memory) | prompt | llm\n",
    "\n",
    "\n",
    "def invoke_chain(question):\n",
    "    result = chain.invoke({\"question\": question})\n",
    "    memory.save_context(\n",
    "        {\"input\": question},\n",
    "        {\"output\": result.content},\n",
    "    )\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸ’€ğŸ•µï¸\\u200dâ™‚ï¸ğŸ”'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"exhumation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='âœˆï¸ğŸ”¥ğŸ˜'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Top Gun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ğŸ¦ˆğŸ–ï¸ğŸš¤'\n"
     ]
    }
   ],
   "source": [
    "invoke_chain(\"Jaws\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDuck search start\n",
      "íŒë‹¤ í•œ ë§ˆë¦¬ì˜ ì„ëŒ€ ë¹„ìš©ì€ ì—°ê°„ 10ì–µ ì´ìƒì´ë©°, ì—¬ê¸°ì— ì¤‘êµ­ì¸ ì‚¬ìœ¡ì‚¬ ì„ëŒ€ ë¹„ìš© [14]ê³¼ ì£½ìˆœ ë° ëŒ€ë‚˜ë¬´ ë“± ì‹ë¹„ìš© [15], í™˜ê²½ ê´€ë¦¬, ê±´ê°• ëŒë´„ ë“± ê¸°íƒ€ ì œë¹„ìš©ì„ í•©í•˜ë©´ 1ë…„ë‹¹ ìˆ˜ì‹­ì–µ ì›ì´ ë“¤ì–´ê°€ê²Œ ëœë‹¤. íŒë‹¤ì›”ë“œìƒµì—ëŠ” ë¬´ë ¤ 100ë§Œì›ì§œë¦¬ íŒë‹¤ í”¼ê·œì–´ê°€ ìˆë‹¤. [16] About this app. arrow_forward. â€» Why you should choose PandaVPN! You can use it for free for one day just by signing up! After logging in, just press Panda to connect to the fastest location, making it very convenient to use! Real-time consultation is available in Korean! Enjoy worry-free streaming at fast speeds! ì—ë²„ëœë“œ ìµœì´ˆë¡œ ìì—°ë¶„ë§Œìœ¼ë¡œ íƒœì–´ë‚œ í‘¸ë°”ì˜¤ ì™€ ìµœì´ˆë¡œ ìŒë‘¥ì´ë¡œ íƒœì–´ë‚œ ë£¨ì´ë°”ì˜¤ ì™€ í›„ì´ë°”ì˜¤ ì˜ ì•„ë¹ ì´ì ë°”ì˜¤ ê°€ì¡± ì˜ ê°€ì¥ì´ë‹¤. ë˜í•œ 2024ë…„ í˜„ì¬ê¹Œì§€ í•œêµ­ì— ì˜¨ ëª¨ë“  íŒë‹¤ë“¤ ì¤‘ ìœ ì¼í•œ ìˆ˜ì»· íŒë‹¤ì´ë‹¤. [11] [12] ì´ë¦„ ëŸ¬ë°”ì˜¤ëŠ” 'ê¸°ì¨ì„ ì£¼ëŠ” ë³´ë¬¼'ì´ë¼ëŠ” ëœ»ìœ¼ë¡œ ... íŒë‹¤. íŒë‹¤ì˜ ìƒíƒœì™€ ì„œì‹ì§€. íŒë‹¤ëŠ” ì¤‘êµ­ì˜ ì¤‘ë‚¨ë¶€ ì‚°ì•…ì§€ëŒ€ì— ì„œì‹í•˜ëŠ” ëŒ€í˜• í¬ìœ ë¥˜ë¡œ, ì£¼ë¡œ ëŒ€ë‚˜ë¬´ë¥¼ ë¨¹ê³  ì‚½ë‹ˆë‹¤. íŒë‹¤ëŠ” ì—„ì²­ë‚œ ì–‘ì˜ ëŒ€ë‚˜ë¬´ë¥¼ ì„­ì·¨í•˜ëŠ”ë°, í•˜ë£¨ì— 12kgì—ì„œ 38kgê¹Œì§€ ë¨¹ëŠ”ë‹¤ê³  í•´ìš”. ì´ ë•Œë¬¸ì— ì„œì‹ì§€ ë‚´ ëŒ€ë‚˜ë¬´ ìˆ²ì€ íŒë‹¤ ìƒì¡´ì— í•„ìˆ˜ì ì´ì£ . íŒë‹¤ ê·€í™˜ ëŸ¬ì‹œê°€ ì‡ë”°ë¥´ë©´ì„œ ì¤‘êµ­ì˜ íŒë‹¤ ì™¸êµë„ ì¢…ì–¸ì„ ê³ í•˜ëŠ” ê²ƒ ì•„ë‹ˆëƒëŠ” ë¶„ì„ë“¤ì´ ë‚˜ì™”ë‹¤. íŒë‹¤ í™”ë©”ì´ê°€ 2000ë…„ 8ì›” ë¯¸êµ­ ìº˜ë¦¬í¬ë‹ˆì•„ì£¼ ìƒŒë””ì—ì´ê³  ë™ë¬¼ì›ì—ì„œ ëŒ€ë‚˜ë¬´ë¥¼ í–¥í•´ íŒ”ì„ ë»—ê³  ìˆë‹¤. apì—°í•©ë‰´ìŠ¤ ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain.utilities.duckduckgo_search import DuckDuckGoSearchAPIWrapper\n",
    "ddg = DuckDuckGoSearchAPIWrapper()\n",
    "print(\"DuckDuck search start\")\n",
    "results = ddg.run(\"íŒë‹¤\")\n",
    "print(results)\n",
    "file_path = f\"MyResearch.txt\"\n",
    "with open(file_path, 'w') as f:\n",
    "    f.write(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
